{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions: 다중 감정 분류 모델 학습\n",
    "\n",
    "이 노트북은 GoEmotions 데이터셋을 사용하여 Reddit 댓글의 다중 감정(27가지)을 분류하는 모델을 학습하고 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers[torch] scikit-learn pandas numpy matplotlib seaborn tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report, multilabel_confusion_matrix\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Hub 로그인 (필요시)\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoEmotions 데이터셋 로드\n",
    "dataset = load_dataset(\"go_emotions\", \"raw\") # 'raw' configuration for original multi-label data\n",
    "\n",
    "print(dataset)\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 정보 확인\n",
    "labels = dataset[\"train\"].features[\"labels\"].feature.names\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "num_labels = len(labels)\n",
    "\n",
    "print(f\"Total labels: {num_labels}\")\n",
    "print(f\"Label names: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 데이터 전처리 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    # 텍스트 토큰화\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    \n",
    "    # 레이블을 multi-hot encoding으로 변환\n",
    "    # examples['labels']는 각 샘플에 대한 레이블 ID의 리스트입니다.\n",
    "    multi_hot_labels = []\n",
    "    for label_list in examples[\"labels\"]:\n",
    "        one_hot_vector = [0.0] * num_labels # float 타입으로 초기화\n",
    "        for label_id in label_list:\n",
    "            if 0 <= label_id < num_labels:\n",
    "                one_hot_vector[label_id] = 1.0\n",
    "        multi_hot_labels.append(one_hot_vector)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = multi_hot_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_data, batched=True, remove_columns=[\"text\", \"id\", \"caller_id\", \"linked_id\", \"created_utc\", \"comment_id\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "print(tokenized_datasets['train'][0])\n",
    "print(tokenized_datasets['train'][0]['labels'].shape)\n",
    "print(tokenized_datasets['train'][0]['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 크기 줄이기 (빠른 테스트용, 필요시 주석 해제)\n",
    "# print(\"Original dataset sizes:\")\n",
    "# print({split: len(tokenized_datasets[split]) for split in tokenized_datasets})\n",
    "\n",
    "# train_subset_size = 1000 \n",
    "# val_subset_size = 200\n",
    "# test_subset_size = 200\n",
    "\n",
    "# tokenized_datasets_subset = DatasetDict({\n",
    "#     'train': tokenized_datasets['train'].shuffle(seed=42).select(range(train_subset_size)),\n",
    "#     'validation': tokenized_datasets['validation'].shuffle(seed=42).select(range(val_subset_size)),\n",
    "#     'test': tokenized_datasets['test'].shuffle(seed=42).select(range(test_subset_size))\n",
    "# })\n",
    "# print(\"\\nSubset dataset sizes:\")\n",
    "# print({split: len(tokenized_datasets_subset[split]) for split in tokenized_datasets_subset})\n",
    "# tokenized_datasets = tokenized_datasets_subset # 실제 학습에 사용할 데이터셋을 부분집합으로 교체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 선택 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=num_labels, \n",
    "    problem_type=\"multi_label_classification\", # 다중 레이블 분류 문제 명시\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# GPU 사용 가능 여부 확인 및 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. 학습 설정 및 메트릭 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 레이블 분류를 위한 메트릭 함수\n",
    "def compute_metrics_multilabel(eval_pred):\n",
    "    logits, true_labels = eval_pred\n",
    "    # 로짓에 시그모이드 함수 적용\n",
    "    probs = torch.sigmoid(torch.Tensor(logits)).numpy()\n",
    "    # 임계값(0.5)을 기준으로 예측 레이블 결정 (0 또는 1)\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    \n",
    "    # true_labels도 float에서 int로 변환 (필요시)\n",
    "    true_labels = true_labels.astype(int)\n",
    "\n",
    "    # F1 score (macro, micro, weighted, samples)\n",
    "    f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    f1_micro = f1_score(true_labels, predictions, average='micro', zero_division=0)\n",
    "    f1_weighted = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    # ROC AUC (macro, micro)\n",
    "    # roc_auc_macro = roc_auc_score(true_labels, probs, average='macro', multi_class='ovo') # 'ovr' or 'ovo'\n",
    "    # roc_auc_micro = roc_auc_score(true_labels, probs, average='micro')\n",
    "    \n",
    "    # 정확도 (모든 레이블이 정확히 일치하는 샘플의 비율 - subset accuracy)\n",
    "    subset_accuracy = accuracy_score(true_labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        # 'roc_auc_macro': roc_auc_macro,\n",
    "        # 'roc_auc_micro': roc_auc_micro,\n",
    "        'subset_accuracy': subset_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 # GPU 메모리에 따라 조정 (예: 8, 16, 32)\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3 # 하루 안에 완료를 위해 에포크 수 조정 (원래는 3-5 추천)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_goemotions\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_dir=\"./logs_goemotions\",\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True, # 가장 좋은 모델을 마지막에 로드\n",
    "    metric_for_best_model=\"f1_macro\", # 가장 좋은 모델 선택 기준\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2, # 저장할 모델 체크포인트 수\n",
    "    fp16=torch.cuda.is_available(), # GPU 사용 시 혼합 정밀도 학습 활성화\n",
    "    report_to=\"tensorboard\", # TensorBoard 로깅\n",
    "    push_to_hub=False # Hugging Face Hub에 모델 푸시 여부\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Trainer 정의 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_multilabel,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] # 성능 개선 없을 시 조기 종료\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard 실행 (Colab 또는 로컬 터미널에서)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs_goemotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 평가 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋으로 평가\n",
    "eval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(\"\\nTest Set Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋으로 예측\n",
    "predictions_output = trainer.predict(tokenized_datasets[\"test\"])\n",
    "logits = predictions_output.predictions\n",
    "true_labels = predictions_output.label_ids\n",
    "\n",
    "# 로짓을 예측 레이블로 변환 (시그모이드 + 임계값)\n",
    "probs = torch.sigmoid(torch.Tensor(logits)).numpy()\n",
    "predicted_labels = (probs > 0.5).astype(int)\n",
    "\n",
    "# true_labels도 float에서 int로 변환 (이미 되어있을 수 있음)\n",
    "true_labels = true_labels.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. 분류 보고서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGoEmotions Multi-label Classification Report (Test Set):\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. 혼동 행렬 (각 레이블별)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 레이블에 대한 혼동 행렬 시각화\n",
    "mcm = multilabel_confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "def plot_confusion_matrix_multilabel(mcm, labels, cols=3):\n",
    "    rows = (len(labels) + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "    axes = axes.flatten() # 다차원 배열을 1차원으로\n",
    "    for i, label_name in enumerate(labels):\n",
    "        if i < len(mcm):\n",
    "            cm = mcm[i]\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                        xticklabels=['Not ' + label_name, label_name],\n",
    "                        yticklabels=['Not ' + label_name, label_name])\n",
    "            axes[i].set_title(f'CM for: {label_name}')\n",
    "            axes[i].set_xlabel('Predicted')\n",
    "            axes[i].set_ylabel('True')\n",
    "        else:\n",
    "            axes[i].axis('off') # 남는 subplot 숨기기\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix_multilabel(mcm, labels, cols=4) # 한 줄에 4개씩 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 샘플 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text, model, tokenizer, id2label, threshold=0.5):\n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    # GPU 사용 가능하면 모델과 입력을 GPU로 이동\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 입력 텍스트 토큰화\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # 로짓에 시그모이드 적용하여 확률 계산\n",
    "    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
    "    \n",
    "    # 임계값을 넘는 레이블 선택\n",
    "    predicted_label_ids = np.where(probs > threshold)[0]\n",
    "    predicted_emotions = [id2label[idx] for idx in predicted_label_ids]\n",
    "    \n",
    "    return predicted_emotions, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"I am so happy and excited about the new project!\",\n",
    "    \"This is really frustrating and annoying.\",\n",
    "    \"I'm not sure how I feel about this, a bit confused and curious.\",\n",
    "    \"Thank you so much, I really appreciate your help.\",\n",
    "    \"The movie was incredibly sad, but also very beautiful.\"\n",
    "]\n",
    "\n",
    "for text in sample_texts:\n",
    "    predicted_emotions, _ = predict_emotion(text, model, tokenizer, id2label, threshold=0.3) # 임계값 조정 가능\n",
    "    print(f\"\\nSample Text: '{text}'\")\n",
    "    if predicted_emotions:\n",
    "        print(f\"Predicted Emotions: {', '.join(predicted_emotions)}\")\n",
    "    else:\n",
    "        print(\"Predicted Emotions: No emotion above threshold (or 'neutral' if available and predicted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 저장 (선택 사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델과 토크나이저 저장\n",
    "output_model_dir = \"./saved_model_goemotions\"\n",
    "os.makedirs(output_model_dir, exist_ok=True)\n",
    "\n",
    "trainer.save_model(output_model_dir)\n",
    "tokenizer.save_pretrained(output_model_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 로드 및 사용 예시 (저장된 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# # 저장된 모델과 토크나이저 로드\n",
    "# loaded_model = AutoModelForSequenceClassification.from_pretrained(output_model_dir)\n",
    "# loaded_tokenizer = AutoTokenizer.from_pretrained(output_model_dir)\n",
    "\n",
    "# # id2label 맵핑 (실제 사용 시 저장/로드 필요)\n",
    "# # 이 예제에서는 위에서 정의된 id2label을 사용합니다.\n",
    "\n",
    "# sample_text_for_loading_test = \"I feel a bit nervous but also excited.\"\n",
    "# predicted_emotions_loaded, _ = predict_emotion(sample_text_for_loading_test, loaded_model, loaded_tokenizer, id2label, threshold=0.3)\n",
    "\n",
    "# print(f\"\\nSample Text (loaded model): '{sample_text_for_loading_test}'\")\n",
    "# if predicted_emotions_loaded:\n",
    "#     print(f\"Predicted Emotions: {', '.join(predicted_emotions_loaded)}\")\n",
    "# else:\n",
    "#     print(\"Predicted Emotions: No emotion above threshold\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
